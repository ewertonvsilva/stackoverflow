{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msGXve8btxnH"
      },
      "source": [
        "## Outline\n",
        "1. Upload the data to the designated GCS bucket\n",
        "  - The data is stored in GCS bucket to simulate a real world scenario. In reality, data is collected in a central location(i.e. GCS bucket), and it will be used measure the model performance. We can measure the model performance much more reliable on a batch data than a single data(online)\n",
        "2. Perform batch prediction\n",
        "3. Measure the model performance(accuracy) on the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ7b4cxjax2q"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heCy5KIqGmN5"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform\n",
        "!pip install google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P28WFWH2GpwG"
      },
      "outputs": [],
      "source": [
        "!gcloud init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v_P4FAjGuGf"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxA2NFvUax2s"
      },
      "source": [
        "## Set Environment Values for GCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y4ZMVcLHHkX"
      },
      "outputs": [],
      "source": [
        "GOOGLE_CLOUD_PROJECT = \"<project-name>\"  # @param {type:\"string\"}\n",
        "GOOGLE_CLOUD_REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "MODEL_NAME = \"untitled_1641902556119_202212010622\"  # @param {type:\"string\"}\n",
        "\n",
        "TEST_FILENAME = \"input.json\"  # @param {type:\"string\"}\n",
        "TEST_GCS_BUCKET = \"gs://<bucket-name>\"  # @param {type:\"string\"}\n",
        "TEST_LOCAL_PATH = \"Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rI5zndHax2t"
      },
      "source": [
        "## Clone the Repository to Obtain Test Images\n",
        "- There are only 10 image files for simple testing purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHcBvji7Rbrs",
        "outputId": "9524c4f8-46e7-4774-a341-a51b805e3580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes'...\n",
            "remote: Enumerating objects: 484, done.\u001b[K\n",
            "remote: Counting objects: 100% (484/484), done.\u001b[K\n",
            "remote: Compressing objects: 100% (404/404), done.\u001b[K\n",
            "remote: Total 484 (delta 300), reused 116 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (484/484), 4.38 MiB | 14.94 MiB/s, done.\n",
            "Resolving deltas: 100% (300/300), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/deep-diver/Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDexvxTXRfWH",
        "outputId": "cd63e161-f62d-423d-fea0-33df9c270e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['horse_0000.jpg',\n",
              " 'bird_0000.jpg',\n",
              " 'cat_0000.jpg',\n",
              " 'frog_0000.jpg',\n",
              " 'dog_0000.jpg',\n",
              " 'truck_0000.jpg',\n",
              " 'automobile_0000.jpg',\n",
              " 'ship_0000.jpg',\n",
              " 'airplane_0000.jpg',\n",
              " 'deer_0000.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from os import listdir\n",
        "\n",
        "test_files = listdir(TEST_LOCAL_PATH)\n",
        "test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1-iNomlax2w"
      },
      "source": [
        "## Create Import File to be Injected into Batch Prediction\n",
        "- Batch request input should follow a certain format in Vertex AI Prediction. JSONL, TFRecord, CSV, file list formats are available([link](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions#batch_request_input)), and file list format is used in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJR9wy6GXyJv"
      },
      "outputs": [],
      "source": [
        "f = open(TEST_FILENAME, \"w\")\n",
        "\n",
        "for filename in test_files:\n",
        "    f.write(f\"{TEST_GCS_BUCKET}/{filename}\\n\")\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmRePB6aYRfR"
      },
      "outputs": [],
      "source": [
        "!cat {TEST_FILENAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRAfbQHJax2x"
      },
      "source": [
        "## Copy Test Images and Import File to GCS Bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdeuJt5YYVPw",
        "outputId": "7d5c90b5-5484-418e-8446-f034797b116d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://test-images.txt [Content-Type=text/plain]...\n",
            "/ [1/1 files][  280.0 B/  280.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/280.0 B.                                      \n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/airplane_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/automobile_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/horse_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/dog_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/frog_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/ship_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/cat_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/bird_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/deer_0000.jpg [Content-Type=image/jpeg]...\n",
            "Copying file://Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/notebooks/test-images/truck_0000.jpg [Content-Type=image/jpeg]...\n",
            "/ [10/10 files][  9.2 KiB/  9.2 KiB] 100% Done                                  \n",
            "Operation completed over 10 objects/9.2 KiB.                                     \n"
          ]
        }
      ],
      "source": [
        "!gsutil -m cp -r {TEST_FILENAME} {TEST_GCS_BUCKET}\n",
        "!gsutil -m cp -r {TEST_LOCAL_PATH}/*.jpg {TEST_GCS_BUCKET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mVFSRUQHdEj"
      },
      "source": [
        "## Batch Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_0QXPfcHc3p"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "from typing import Union, Sequence\n",
        "\n",
        "\n",
        "def create_batch_prediction_job_dedicated_resources_sample(project: str,location: str,model_resource_name: str,job_display_name: str,gcs_source: Union[str, Sequence[str]], gcs_destination: str,instances_format: str = \"jsonl\",machine_type: str = \"n1-standard-2\", accelerator_count: int = 1, accelerator_type: str = \"NVIDIA_TESLA_K80\", starting_replica_count: int = 1, max_replica_count: int = 1, sync: bool = True,):\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    my_model = aiplatform.Model(model_resource_name)\n",
        "\n",
        "    batch_prediction_job = my_model.batch_predict(\n",
        "        job_display_name=job_display_name,\n",
        "        instances_format=instances_format,\n",
        "        gcs_source=gcs_source,\n",
        "        gcs_destination_prefix=gcs_destination,\n",
        "        machine_type=machine_type,\n",
        "        accelerator_count=accelerator_count,\n",
        "        accelerator_type=accelerator_type,\n",
        "        starting_replica_count=starting_replica_count,\n",
        "        max_replica_count=max_replica_count,\n",
        "        sync=sync,\n",
        "    )\n",
        "\n",
        "    return batch_prediction_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkAJqucqaw_r"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb1g6qdNLTfP",
        "outputId": "03c42784-5e02-427b-a2ed-972d69607de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.aiplatform.jobs.BatchPredictionJob object at 0x7f5019d08bd0> is waiting for upstream dependencies to complete."
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "create_batch_prediction_job_dedicated_resources_sample(\n",
        "    project=GOOGLE_CLOUD_PROJECT,\n",
        "    location=GOOGLE_CLOUD_REGION,\n",
        "    model_resource_name=\"67033<resource id here>2576\",\n",
        "    job_display_name=f\"batch_training-{TIMESTAMP}\",\n",
        "    gcs_source=f'{TEST_GCS_BUCKET}/{TEST_FILENAME}',\n",
        "    gcs_destination=f\"{TEST_GCS_BUCKET}/results/\",\n",
        "    accelerator_type=None,\n",
        "    accelerator_count=None,\n",
        "    sync=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mq5Pjm-ax2z"
      },
      "source": [
        "## Evaluate Batch Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Hz7CVqbE5o",
        "outputId": "08df5dd9-79b1-458b-aa63-b393eee60238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T19_24_05_801Z/prediction.results-00000-of-00001...\n",
            "/ [0/6 files][    0.0 B/  1.3 KiB]   0% Done                                    \r",
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T18_47_39_122Z/prediction.results-00000-of-00001...\n",
            "/ [0/6 files][    0.0 B/  1.3 KiB]   0% Done                                    \r",
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T18_47_39_122Z/prediction.errors_stats-00000-of-00001...\n",
            "/ [0/6 files][    0.0 B/  1.3 KiB]   0% Done                                    \r",
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T19_23_55_003Z/prediction.errors_stats-00000-of-00001...\n",
            "/ [0/6 files][    0.0 B/  1.3 KiB]   0% Done                                    \r",
            "/ [1/6 files][    0.0 B/  1.3 KiB]   0% Done                                    \r",
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T19_23_55_003Z/prediction.results-00000-of-00001...\n",
            "Copying gs://batch-prediction-collection/results/prediction-resnet_cifar_latest-2021_09_16T19_24_05_801Z/prediction.errors_stats-00000-of-00001...\n",
            "/ [6/6 files][  1.3 KiB/  1.3 KiB] 100% Done                                    \n",
            "Operation completed over 6 objects/1.3 KiB.                                      \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "RESULTS_DIRECTORY = \"results\"\n",
        "RESULTS_DIRECTORY_FULL = f'{TEST_GCS_BUCKET}/{RESULTS_DIRECTORY}'\n",
        "\n",
        "# Create missing directories\n",
        "os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
        "\n",
        "# Get the Cloud Storage paths for each result\n",
        "!gsutil -m cp -r $RESULTS_DIRECTORY_FULL $RESULTS_DIRECTORY\n",
        "\n",
        "# Get most recently modified directory\n",
        "latest_directory = max(\n",
        "    [\n",
        "        os.path.join(RESULTS_DIRECTORY, d)\n",
        "        for d in os.listdir(RESULTS_DIRECTORY)\n",
        "    ],\n",
        "    key=os.path.getmtime,\n",
        ")\n",
        "\n",
        "# Get downloaded results in directory\n",
        "results_files = []\n",
        "for dirpath, subdirs, files in os.walk(latest_directory):\n",
        "    for file in files:\n",
        "        if file.startswith(\"prediction.results\"):\n",
        "            results_files.append(os.path.join(dirpath, file))\n",
        "\n",
        "# Consolidate all the results into a list\n",
        "results = []\n",
        "for results_file in results_files:\n",
        "    # Download each result\n",
        "    with open(results_file, \"r\") as file:\n",
        "        results.extend([json.loads(line) for line in file.readlines()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCHYk8L0p6ED",
        "outputId": "ca9348c1-db4e-43e2-cf41-1a066d727389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'instance': 'gs://batch-prediction-collection/airplane_0000.jpg',\n",
              "  'prediction': {'confidence': 0.635806859, 'label': 'ship'}},\n",
              " {'instance': 'gs://batch-prediction-collection/cat_0000.jpg',\n",
              "  'prediction': {'confidence': 0.514597297, 'label': 'cat'}},\n",
              " {'instance': 'gs://batch-prediction-collection/ship_0000.jpg',\n",
              "  'prediction': {'confidence': 0.944843113, 'label': 'ship'}},\n",
              " {'instance': 'gs://batch-prediction-collection/bird_0000.jpg',\n",
              "  'prediction': {'confidence': 0.710508406, 'label': 'horse'}},\n",
              " {'instance': 'gs://batch-prediction-collection/truck_0000.jpg',\n",
              "  'prediction': {'confidence': 0.980968714, 'label': 'truck'}},\n",
              " {'instance': 'gs://batch-prediction-collection/frog_0000.jpg',\n",
              "  'prediction': {'confidence': 0.696931422, 'label': 'frog'}},\n",
              " {'instance': 'gs://batch-prediction-collection/dog_0000.jpg',\n",
              "  'prediction': {'confidence': 0.382295936, 'label': 'cat'}},\n",
              " {'instance': 'gs://batch-prediction-collection/deer_0000.jpg',\n",
              "  'prediction': {'confidence': 0.437720776, 'label': 'dog'}},\n",
              " {'instance': 'gs://batch-prediction-collection/automobile_0000.jpg',\n",
              "  'prediction': {'confidence': 0.460335433, 'label': 'automobile'}},\n",
              " {'instance': 'gs://batch-prediction-collection/horse_0000.jpg',\n",
              "  'prediction': {'confidence': 0.918733776, 'label': 'dog'}}]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-6UdwcKqDKO",
        "outputId": "4545ebf3-71fa-477f-8c51-1068a6d65226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label(airplane)/prediction(ship)\n",
            "label(cat)/prediction(cat)\n",
            "label(ship)/prediction(ship)\n",
            "label(bird)/prediction(horse)\n",
            "label(truck)/prediction(truck)\n",
            "label(frog)/prediction(frog)\n",
            "label(dog)/prediction(cat)\n",
            "label(deer)/prediction(dog)\n",
            "label(automobile)/prediction(automobile)\n",
            "label(horse)/prediction(dog)\n",
            "\n",
            "number of results: 10\n",
            "number of correct: 5\n",
            "Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "num_correct = 0\n",
        "\n",
        "for result in results:\n",
        "    label = os.path.basename(result[\"instance\"]).split(\"_\")[0]\n",
        "    prediction = result[\"prediction\"][\"label\"]\n",
        "\n",
        "    print(f\"label({label})/prediction({prediction})\")\n",
        "    if label == prediction:\n",
        "        num_correct = num_correct + 1\n",
        "\n",
        "print()\n",
        "print(f\"number of results: {len(results)}\")\n",
        "print(f\"number of correct: {num_correct}\")\n",
        "print(f\"Accuracy: {num_correct/len(results)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of 03_Batch_Prediction_Performance.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
